<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>B树索引与位图索引</title>
    <url>/2015/01/B-tree-indexes-and-bitmap-indexes/</url>
    <content><![CDATA[<h3 id="简说"><a class="markdownIt-Anchor" href="#简说"></a> 简说</h3>
<p>在理解索引时，可以想象一本书，其中书的内容就相当于表里的数据，而书前面的目录就相当于该表的索引。<br />
同时，通常情况下，索引所占用的磁盘空间要比表要小得多，其主要作用是为了加快对数据的搜索速度，也可以用来保证数据的唯一性。<br />
普遍运用在数据库和文件系统。</p>
<p>索引作为一种可选的数据结构，你可以选择为某个表里的创建索引，也可以不创建。这是因为一旦创建了索引，就意味着数据库对表进行DML（包括INSERT、UPDATE、DELETE）时，必须处理额外的工作量（也就是对索引结构的维护）以及存储方面的开销。所以创建索引时，需要考虑创建索引所带来的查询性能方面的提高，与引起的额外的开销相比，是否值得。</p>
<p>从物理上说，索引通常可以分为：常规B树索引、位图（bitmap）索引、翻转（reverse）索引等等…</p>
<h3 id="b树索引"><a class="markdownIt-Anchor" href="#b树索引"></a> B树索引</h3>
<p>即二叉搜索树，也是一种树状数据结构；	<br />
大量的数据库（如MySQL、oracle、PostgreSQL等）都在使用B树。B树索引本质上是对索引字段进行排序，然后通过类似二分查找的方法进行快速查找，即它要求索引的字段是可排序的，一般而言，可排序的是一维字段，比如时间、身份证号码  手机号码、QQ等等。</p>
<p><strong>数据结构</strong>：<br />
<img data-src="http://cdn.jasonsoso.com/b.jpg" alt="" /></p>
<p><strong>特点</strong>：</p>
<ol>
<li>索引不存储null值，单一索引不存储null值，复合索引不存储全为null的值；</li>
<li>不适合键值较少的列（重复数据较多的列）；比如时间、身份证、手机、QQ等</li>
<li>前导模糊查询不能利用索引(like '%XX’或者like ‘%XX%’)</li>
</ol>
<h3 id="位图索引"><a class="markdownIt-Anchor" href="#位图索引"></a> 位图索引</h3>
<p>我们知道计算机所有信息最终都是通过“位bit”来运算的，二进制位运算在计算机中非常高效。而位图索引也是用0或1来处理索引进程，故得名位图索引。<br />
位图索引主要针对大量相同值的列而创建的，索引块的一个索引行中存储键值、起止RowId及此键值的位图，根据位图信息可以得知每一条记录的ROWID。它为列的每个键值建立位图，位图中的每一位可能对应多个列，位图中位的值为1表示此行的值为对应的键值。</p>
<p><strong>特点</strong>：</p>
<ol>
<li>可以存储null值；</li>
<li>不适合键值较多的列（重复数据较少的列）,适合只有几个固定值的列；如性别、婚姻状况、行政区等等</li>
<li>相对于B*Tree索引,占用的空间非常小,创建和使用非常快；</li>
<li>适合静态数据，而不适合索引频繁更新的列；</li>
<li>使用count、and、or或in查询时,直接用索引的位图进行或运算,快速得出结果行数据。</li>
</ol>
]]></content>
      <tags>
        <tag>数据结构</tag>
        <tag>B树</tag>
        <tag>位图</tag>
      </tags>
  </entry>
  <entry>
    <title>Gitbook（一）：从github到kindle</title>
    <url>/2015/02/gitbook-1/</url>
    <content><![CDATA[<h3 id="简说"><a class="markdownIt-Anchor" href="#简说"></a> 简说</h3>
<p><a href="https://www.gitbook.io/">gitbook</a>是一个用于发布书籍的平台。</p>
<p>gitbook提供了一个简单的命令行工具<code>gitbook</code>用来编译和预览的书籍.</p>
<p><a href="https://nodei.co/npm/gitbook/"><img data-src="http://cdn.jasonsoso.com/201502/gitbook.png" alt="NPM" /></a></p>
<p>其中有如下特点，</p>
<ol>
<li>用<a href="http://git-scm.com/" title="git">git</a>进行版本管理和发布工具，可以托管在<a href="https://github.com/" title="github">github</a>上进行多人协助；</li>
<li>以Markdown轻量级的标记语法进行编写的基础；</li>
<li>用nodejs进行构建部署（gitbook），并且可以发布到gitbook官网上；</li>
<li>可以快速转制各种格式流通的电子书格式：PDF, ePub, mobi（Amazon专属格式），或者也可以生成一个线上阅读网站；</li>
</ol>
<h3 id="安装"><a class="markdownIt-Anchor" href="#安装"></a> 安装</h3>
<ol>
<li>
<p>安装nodejs环境，请到<a href="http://nodejs.org/download/" title="nodejs">nodejs</a>官网进行下载安装<br />
<img data-src="http://cdn.jasonsoso.com/2015/nodejs.png" alt="windows nodejs" /></p>
</li>
<li>
<p>安装gitbook环境</p>
</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">npm install -g gitbook</span><br></pre></td></tr></table></figure>
<p>gitbook提供了如下命令:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">build [options] [source_dir] 编译指定目录，输出Web格式(_book文件夹中)    </span><br><span class="line">serve [options] [source_dir] 监听文件变化并编译指定目录，同时会创建一个服务器用于预览Web    </span><br><span class="line">pdf [options] [source_dir] 编译指定目录，输出PDF    </span><br><span class="line">epub [options] [source_dir] 编译指定目录，输出epub	    </span><br><span class="line">mobi [options] [source_dir] 编译指定目录，输出mobi	    </span><br><span class="line">init [source_dir]   通过SUMMARY.md生成作品目录    </span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><img data-src="http://cdn.jasonsoso.com/2015/gitbook2.png" alt="gitbook" /></p>
<h3 id="书写"><a class="markdownIt-Anchor" href="#书写"></a> 书写</h3>
<p>我暂时没有书写，我现在只是拿来主义</p>
<h3 id="发布"><a class="markdownIt-Anchor" href="#发布"></a> 发布</h3>
<ol>
<li>
<p>gitbook的命令行工具不提供对发布操作的支持，你可以直接使用<code>git</code>发布，<br />
在push成功后，gitbook.io会自动在服务端进行build. 你可以在gitbook.io的个人主页上查看到build信息.</p>
</li>
<li>
<p>生成PDF, ePub, mobi</p>
</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">gitbook pdf</span><br><span class="line">gitbook epub</span><br><span class="line">gitbook mobi</span><br></pre></td></tr></table></figure>
<p>以上命令需要calibre的安装，Calibre是一个开源的“一站式”的电子书解决方案，它可以全面满足你的电子书需求。Calibre是免费的，源代码开放，拥有跨平台的设计。<br />
Gitbook会使用其中的ebook-convert功能组件来完成书籍格式的转换。<br />
登录calibre官网http://www.calibre-ebook.com/，下载安装。</p>
<h3 id="拿来主义"><a class="markdownIt-Anchor" href="#拿来主义"></a> 拿来主义</h3>
<p>因为gitbook上的书太好了，我想用kindle看，我看中了这本书《Elasticsearch权威指南中文版》</p>
<ol>
<li>从github上克隆源码</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/looly/elasticsearch-definitive-guide-cn.git</span><br></pre></td></tr></table></figure>
<ol start="2">
<li>进入源码目录</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> elasticsearch-definitive-guide-cn</span><br></pre></td></tr></table></figure>
<ol start="3">
<li>生成mobi格式</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">gitbook pdf</span><br><span class="line">gitbook mobi <span class="comment"># 生成mobi格式，此格式为Kindle专属格式</span></span><br></pre></td></tr></table></figure>
<ol start="4">
<li>复制mobi格式的文件到kindle，OK！搞定！enjoy it！<br />
<img data-src="http://cdn.jasonsoso.com/2015/IMG_20150202_171118.jpg" alt="my kindle" /></li>
</ol>
]]></content>
      <tags>
        <tag>github</tag>
        <tag>gitbook</tag>
        <tag>nodejs</tag>
        <tag>kindle</tag>
      </tags>
  </entry>
  <entry>
    <title>论框架设计(一)</title>
    <url>/2015/02/design-1/</url>
    <content><![CDATA[<h3 id="web"><a class="markdownIt-Anchor" href="#web"></a> Web</h3>
<ol>
<li>MVC Framwork:<a href="http://docs.spring.io/spring/docs/current/spring-framework-reference/html/mvc.html" title="SpringMVC">SpringMVC</a>，Restful的风格，对比Strus2更简单，更友好。</li>
<li>CSS Framwork：最热火的<a href="http://getbootstrap.com/" title="Bootstrap">Twitter Bootstrap</a>，提供了简便的布局能力和基本的页面美化。</li>
<li>Javascript Library：随大流用了<a href="http://jquery.com/" title="jquery">JQuery</a></li>
<li>Validation Framwork:当然用<a href="http://jqueryvalidation.org/" title="jquery validation">jQuery Validation</a>,客户端校验和体验都不错！</li>
</ol>
<h3 id="database"><a class="markdownIt-Anchor" href="#database"></a> Database</h3>
<ol>
<li>
<p>数据库设计一般性原则</p>
<ol>
<li>主键的列名统一为id。</li>
<li>为方便数据操作及维护，不建立任何外键，用程序去保证关联关系。</li>
<li>为表名添加前缀以便日后管理。比如有几十个表，将联系比较紧密的表，使用相同的前缀。</li>
<li>表名全小写，因为MySQL在Linux下默认区分表名大小写。</li>
</ol>
</li>
<li>
<p>传统关系型数据库</p>
<ol>
<li>MySql，Postgresql</li>
<li>Oracle</li>
</ol>
</li>
<li>
<p>流行的NoSql</p>
<ol>
<li><a href="http://www.mongodb.org/" title="mongodb">MongoDB</a>，最流行Nosql，一个分布式，面向文档的开源数据库，将数据存成BSON格式，与关系型数据库最为相似，也提供类似SQL的查询语句，更像个schema-less的数据库。</li>
<li><a href="http://redis.io/" title="redis">Redis</a>，一个基于内存的缓存数据库，提供强大的TTL等功能，Redis不仅仅支持简单的k/v类型的数据，同时还提供list，set，hash等数据结构的存储。</li>
<li><a href="http://ssdb.io/" title="ssdb">SSDB</a>，基于磁盘高速数据库（国产），号称一个高性能的支持丰富数据结构的 NoSQL 数据库代替Redis。</li>
<li><a href="http://hbase.apache.org/" title="hbase">HBase</a>，一个分布式的、面向列的开源数据库，该技术来源于Google论文“Bigtable：一个结构化数据的分布式存储系统”。</li>
</ol>
</li>
<li>
<p>本地缓存Cache</p>
<ol>
<li>在JVM里的缓存，最老牌的就是Ehcache；</li>
<li>另外最简单的是<a href="http://code.google.com/p/guava-libraries/" title="guava">Guava</a>的Cache，也提供TTL；</li>
</ol>
</li>
<li>
<p>ORM框架</p>
<ol>
<li><a href="http://mybatis.github.io/mybatis-3/zh/index.html" title="mybatis">MyBatis</a>,追求高性能的应用，代码与SQL分离管理，相对码农来说更友好，个人推荐的ORM。</li>
<li><a href="http://hibernate.org/" title="hibernate">Hibernate</a>，最流行的ORM框架，无论是JPA还是Hibernate（当然JPA的实现还是用Hibernate），都是码农界里面最快速开发的东西。</li>
</ol>
</li>
</ol>
<h3 id="search-engine"><a class="markdownIt-Anchor" href="#search-engine"></a> Search Engine</h3>
<ol>
<li><a href="http://www.elasticsearch.org/" title="elasticsearch">Elasticsearch</a>,一个基于Lucene构建的开源，分布式，RESTful搜索引擎;设计用于云计算；能够达到实时搜索，稳定，可靠，快速。本人喜欢这个。</li>
<li><a href="http://lucene.apache.org/solr/" title="solr">Solr</a>,一个基于Lucene构建的开源，最流行的，最快的搜索引擎。</li>
</ol>
<h3 id="services"><a class="markdownIt-Anchor" href="#services"></a> Services</h3>
<ol>
<li>
<p>Security Framework</p>
<ol>
<li><a href="http://shiro.apache.org/" title="shiro">Apache Shiro</a>，个人推荐，比Spring Security简单，容易扩展。</li>
<li>Spring Security， 老牌的安全权限框架。</li>
</ol>
</li>
<li>
<p>Schedule</p>
<ol>
<li><a href="http://quartz-scheduler.org/" title="quartz-scheduler">Quartz</a>，最推荐这个。</li>
<li>Spring Schedule spring自带的轻量级定时调度器</li>
</ol>
</li>
</ol>
<h3 id="utilizes"><a class="markdownIt-Anchor" href="#utilizes"></a> Utilizes</h3>
<ol>
<li>General 常规包
<ol>
<li><a href="http://commons.apache.org/proper/commons-lang/" title="commons-lang">Apache Commons Lang</a>,这也太黏码农了，陪伴着码农长大的Jar。</li>
<li><a href="http://code.google.com/p/guava-libraries/" title="guava">Guava</a>，Google新鲜出炉的优雅产品，有点新潮，Java8好多基础Class都收此为囊中。</li>
<li><a href="http://commons.apache.org/proper/commons-io/" title="commons-io">Apache Commons IO</a>， 同样好使。</li>
<li><a href="http://commons.apache.org/proper/commons-fileupload/" title="commons-fileupload">Commons FileUpload</a>，基础上传文件包。</li>
</ol>
</li>
<li>XML
<ol>
<li>JDK JAXB ,JDK自带</li>
<li><a href="http://xstream.codehaus.org/" title="xstream">Xstream</a> ,以轻易的将Java对象和xml文档相互转换,而且可以修改某个特定的属性和节点名称,而且也支持json的转换。</li>
</ol>
</li>
<li>JSON
<ol>
<li><a href="http://code.google.com/p/google-gson/" title="google-gson">GSon</a>,出身名门，出于Google之手，接口优雅。</li>
<li><a href="http://jackson.codehaus.org/" title="jackson">Jackson</a>，功能丰富，相对快，Spring默认用它，所以我一直都用他。</li>
<li><a href="https://github.com/alibaba/fastjson" title="fastjson">Fastjson</a>，出于阿里人之手，号称全球最快的Json处理框架。</li>
</ol>
</li>
<li>Logging
<ol>
<li>Slf4j,早就替代了Apache Common Logging了,个人一直用它Log日志。</li>
<li>Logback，Log4j作者的后作Logback就好很多了，另外选择Logstash做日志的中央式处理。</li>
</ol>
</li>
<li>HttpClient
<ol>
<li>JDK URL，JDK原生的URL请求。</li>
<li>Apache HttpClient，建议用Apache HttpClient好过JDK自带。</li>
</ol>
</li>
<li>Serializer
<ol>
<li>JDK Serializer</li>
<li>Jackson Serializer</li>
<li><a href="http://thrift.apache.org/" title="thrift">Thrift</a>，出自Facebook，跨语言，推荐</li>
<li><a href="http://avro.apache.org/" title="avro">Avro</a>，出自Hadoop之父Doug Cutting，跨语言，推荐</li>
</ol>
</li>
</ol>
<h3 id="test"><a class="markdownIt-Anchor" href="#test"></a> Test</h3>
<ol>
<li>Unit Test:Junit正统Java测试用例框架，AssertJ 是目前最好的Assert语句库。</li>
<li>Performance/Stability Test：[Jmeter]作为测试工具是最成熟，常用于压力测试，并发测试等等。</li>
</ol>
]]></content>
      <tags>
        <tag>框架</tag>
      </tags>
  </entry>
  <entry>
    <title>Hadoop学习（一）Hadoop2.6.0伪分布式安装与配置</title>
    <url>/2015/05/install-hadoop/</url>
    <content><![CDATA[<h3 id="环境"><a class="markdownIt-Anchor" href="#环境"></a> 环境</h3>
<h4 id="准备ubuntu-1404-lts-并更新apt"><a class="markdownIt-Anchor" href="#准备ubuntu-1404-lts-并更新apt"></a> 准备Ubuntu 14.04 LTS  并更新apt</h4>
<ol>
<li>执行</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo apt-get update</span><br></pre></td></tr></table></figure>
<ol start="2">
<li>可更改数据源进行update</li>
</ol>
<h4 id="设置静态ip地址"><a class="markdownIt-Anchor" href="#设置静态ip地址"></a> 设置静态IP地址</h4>
<p>必须设置静态IP，为以后的集群，分布式等做铺垫</p>
<ol>
<li>编辑interfaces文件</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo vi /etc/network/interfaces</span><br></pre></td></tr></table></figure>
<ol start="2">
<li>写入如下:</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#如果做集群，则192.168.1.100此IP为主节点</span></span><br><span class="line">auto eth0</span><br><span class="line">iface eth0 inet static</span><br><span class="line">address 192.168.1.100 	<span class="comment">#IP地址		</span></span><br><span class="line">gateway 192.168.1.1 	<span class="comment">#网关	</span></span><br><span class="line">netmask 255.255.255.0</span><br><span class="line">network 192.168.1.0	</span><br><span class="line">broadcast 192.168.1.255</span><br><span class="line">	</span><br><span class="line"><span class="comment">#如果做集群，则192.168.1.101此IP为从节点</span></span><br><span class="line">auto eth0</span><br><span class="line">iface eth0 inet static</span><br><span class="line">address 192.168.1.101 	<span class="comment">#IP地址		</span></span><br><span class="line">gateway 192.168.1.1 	<span class="comment">#网关	</span></span><br><span class="line">netmask 255.255.255.0</span><br><span class="line">network 192.168.1.0	</span><br><span class="line">broadcast 192.168.1.255</span><br></pre></td></tr></table></figure>
<h4 id="修改hostname"><a class="markdownIt-Anchor" href="#修改hostname"></a> 修改HostName</h4>
<ol>
<li>编辑hostname文件</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo vi /etc/hostname</span><br></pre></td></tr></table></figure>
<ol start="2">
<li>写入<code>ubuntu</code></li>
<li>那么ubuntu就是本机器的主机名，可以<code>hostname</code>进行查看</li>
</ol>
<h4 id="ip与hostname绑定"><a class="markdownIt-Anchor" href="#ip与hostname绑定"></a> IP与HostName绑定</h4>
<ol>
<li>执行</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo vi /etc/hosts</span><br></pre></td></tr></table></figure>
<ol start="2">
<li>写入如下：</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#如果做集群，则192.168.1.101此IP为从节点</span></span><br><span class="line">192.168.1.100 hadoop-yarn.jasonsoso.com hadoop-yarn master</span><br><span class="line"></span><br><span class="line"><span class="comment">#如果做集群，则192.168.1.101此IP为从节点</span></span><br><span class="line">192.168.1.101 slave1.jasonsoso.com slave1</span><br></pre></td></tr></table></figure>
<ol start="3">
<li>那么访问<code>hadoop-yarn.jasonsoso.com</code>则访问IP为<code>192.168.1.100</code>的机器</li>
</ol>
<h4 id="创建hadoop系统用户"><a class="markdownIt-Anchor" href="#创建hadoop系统用户"></a> 创建hadoop系统用户</h4>
<p>如果你安装 Ubuntu 的时候不是用的 hadoop 用户，那么最好增加一个名为 hadoop 的用户，密码可设置为 123456 (密码随意指定)。</p>
<ol>
<li>创建新用户</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo useradd -m hadoop -s /bin/bash</span><br></pre></td></tr></table></figure>
<ol start="2">
<li>修改密码</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo passwd hadoop</span><br></pre></td></tr></table></figure>
<ol start="3">
<li>为 hadoop 用户增加管理员权限，方便部署</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo adduser hadoop sudo</span><br></pre></td></tr></table></figure>
<h4 id="sun-jdk-7"><a class="markdownIt-Anchor" href="#sun-jdk-7"></a> Sun JDK 7</h4>
<p>详情请参考 <a href="http://www.cnblogs.com/fnng/archive/2013/01/30/2883815.html" title="ubuntu下配置java环境">ubuntu下配置java环境</a> 和 <a href="http://www.webupd8.org/2012/06/how-to-install-oracle-java-7-in-debian.html" title="HOW TO INSTALL ORACLE JAVA 7 IN DEBIAN VIA REPOSITORY">HOW TO INSTALL ORACLE JAVA 7 IN DEBIAN VIA REPOSITORY</a></p>
<h4 id="安装ssh-server-配置ssh无密码登陆"><a class="markdownIt-Anchor" href="#安装ssh-server-配置ssh无密码登陆"></a> 安装SSH server、配置SSH无密码登陆</h4>
<ol>
<li>执行安装</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo apt-get install openssh-server</span><br></pre></td></tr></table></figure>
<ol start="2">
<li>登陆本机</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ssh localhost</span><br></pre></td></tr></table></figure>
<ol start="3">
<li>配置SSH无密码登陆</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo ssh-keygen -t rsa		<span class="comment"># 生成密钥	</span></span><br><span class="line">sudo ssh-copy-id ubuntu@localhost	<span class="comment"># 拷贝密钥到某台机器		</span></span><br><span class="line">sudo ssh localhost	<span class="comment">#进行无密码登陆	</span></span><br></pre></td></tr></table></figure>
<ol start="4">
<li>如果做集群，则配置SSH无密码登陆，实现多机器互通</li>
</ol>
<h3 id="hadoop260安装"><a class="markdownIt-Anchor" href="#hadoop260安装"></a> hadoop2.6.0安装</h3>
<ol>
<li>下载hadoop2.6.0	<br />
官网hadoop下载http://hadoop.apache.org/releases.html</li>
<li>解压tar包</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo tar -zxvf ./hadoop-2.6.0.tar.gz -C /opt/hadoop  <span class="comment"># 解压到/opt/hadoop中</span></span><br></pre></td></tr></table></figure>
<pre><code>则hadoop的安装根目录为：`/opt/hadoop/hadoop-2.6.0`
</code></pre>
<ol start="3">
<li>修改文件权限</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo <span class="built_in">chown</span> -R hadoop:hadoop ./hadoop-2.6.0</span><br></pre></td></tr></table></figure>
<h3 id="配置"><a class="markdownIt-Anchor" href="#配置"></a> 配置</h3>
<ol>
<li>配置环境变量	<br />
下面<code>#set Hadoop</code>才是真正的hadoop配置，而<code>#set java environment</code>是必须的java环境变量，<code>#set findbugs</code>、<code>#set ant</code>、<code>#PROTOBUF</code>和<code>#set maven environment</code>是编译hadoop代码必须的，现在没有编译hadoop源码，只需要java环境和hadoop环境足矣。</li>
</ol>
<p>执行<code>sudo vi /etc/profile</code>修改profile文件			<br />
添加如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#set java environment</span></span><br><span class="line">JAVA_HOME=/usr/java/jdk1.7.0_60</span><br><span class="line"><span class="built_in">export</span> JRE_HOME=/usr/java/jdk1.7.0_60/jre</span><br><span class="line"><span class="built_in">export</span> CLASSPATH=.:<span class="variable">$JAVA_HOME</span>/lib:<span class="variable">$JRE_HOME</span>/lib:<span class="variable">$CLASSPATH</span></span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$JAVA_HOME</span>/bin:<span class="variable">$JRE_HOME</span>/bin:<span class="variable">$PATH</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#set findbugs</span></span><br><span class="line"><span class="built_in">export</span> LD_LIBRARY_PATH=/usr/local/lib/</span><br><span class="line"><span class="built_in">export</span> FINDBUGS_HOME=/usr/local/findbugs-3.0.0</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$FINDBUGS_HOME</span>/bin</span><br><span class="line"></span><br><span class="line"><span class="comment">#set ant</span></span><br><span class="line">ANT_HOME=/usr/local/apache-ant-1.9.4</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$ANT_HOME</span>/bin</span><br><span class="line"></span><br><span class="line"><span class="comment">#PROTOBUF</span></span><br><span class="line"><span class="built_in">export</span> PROTOC_HOME=/usr/local/protobuf-2.5.0</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$PROTOC_HOME</span>/bin</span><br><span class="line"><span class="built_in">export</span> LD_LIBRARY_PATH=<span class="variable">$LD_LIBRARY_PATH</span>:<span class="variable">$PROTOC_HOME</span>/lib`</span><br><span class="line">	</span><br><span class="line"><span class="comment">#set maven environment</span></span><br><span class="line">M2_HOME=/usr/maven/apache-maven-3.0.5</span><br><span class="line"><span class="built_in">export</span> MAVEN_OPTS=<span class="string">&quot;-Xms256m -Xmx512m&quot;</span></span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$M2_HOME</span>/bin:<span class="variable">$PATH</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#set Hadoop</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_HOME=/opt/hadoop/hadoop-2.6.0</span><br><span class="line"><span class="built_in">export</span> HADOOP_INSTALL=<span class="variable">$HADOOP_HOME</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_MAPRED_HOME=<span class="variable">$HADOOP_HOME</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_COMMON_HOME=<span class="variable">$HADOOP_HOME</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_HDFS_HOME=<span class="variable">$HADOOP_HOME</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_YARN_HOME=<span class="variable">$HADOOP_HOME</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_COMMON_LIB_NATIVE_DIR=<span class="variable">$HADOOP_HOME</span>/lib/native</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$HADOOP_HOME</span>/sbin:<span class="variable">$HADOOP_HOME</span>/bin</span><br></pre></td></tr></table></figure>
<ol start="2">
<li><a href="http://hadoop-env.sh">hadoop-env.sh</a></li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/java/jdk1.7.0_60		</span><br><span class="line"><span class="built_in">export</span> HADOOP_HOME=/opt/hadoop/hadoop-2.6.0</span><br></pre></td></tr></table></figure>
<ol start="3">
<li><a href="http://yarn-env.sh">yarn-env.sh</a></li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/java/jdk1.7.0_60		</span><br><span class="line"><span class="built_in">export</span> HADOOP_HOME=/opt/hadoop/hadoop-2.6.0</span><br></pre></td></tr></table></figure>
<ol start="4">
<li><a href="http://mapred-env.sh">mapred-env.sh</a></li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/java/jdk1.7.0_60		</span><br><span class="line"><span class="built_in">export</span> HADOOP_HOME=/opt/hadoop/hadoop-2.6.0</span><br></pre></td></tr></table></figure>
<ol start="5">
<li>core-site.xml</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">	&lt;name&gt;fs.default.name&lt;/name&gt;</span><br><span class="line">	&lt;value&gt;hdfs://hadoop-yarn.dragon.org:8020&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">		&lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</span><br><span class="line">		&lt;value&gt;/opt/modules/hadoop-2.2.0/data/tmp&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>
<ol start="6">
<li>hdfs-site.xml</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&lt;property&gt;		</span><br><span class="line">		&lt;name&gt;dfs.replication&lt;/name&gt;</span><br><span class="line">		&lt;value&gt;1&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">              &lt;name&gt;dfs.permissions&lt;/name&gt;</span><br><span class="line">              &lt;value&gt;<span class="literal">false</span>&lt;/value&gt;</span><br><span class="line">      &lt;/property&gt;</span><br></pre></td></tr></table></figure>
<ol start="7">
<li>yarn-site.xml</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">	&lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</span><br><span class="line">	&lt;value&gt;mapreduce_shuffle&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>
<ol start="8">
<li>mapred-site.xml</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&lt;property&gt;	 	        		</span><br><span class="line">	&lt;name&gt;mapreduce.framework.name&lt;/name&gt;</span><br><span class="line">	&lt;value&gt;yarn&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>
<h3 id="启动"><a class="markdownIt-Anchor" href="#启动"></a> 启动</h3>
<ol>
<li>
<p>启动HDFS(NameNode、DataNode、SecondaryNameNode)</p>
<ul>
<li>NameNode 格式化</li>
</ul>
</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">bin/hdfs namenode -format</span><br></pre></td></tr></table></figure>
<pre><code>- 启动NameNode
</code></pre>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sbin/hadoop-daemon.sh start namenode</span><br></pre></td></tr></table></figure>
<pre><code>- 启动DataNode
</code></pre>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sbin/hadoop-daemon.sh start datanode</span><br></pre></td></tr></table></figure>
<pre><code>- 启动SecondaryNameNode
</code></pre>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sbin/hadoop-daemon.sh start secondarynamenode</span><br></pre></td></tr></table></figure>
<ol start="2">
<li>启动YARN(ResourceManager、NodeManager)
<ul>
<li>启动ResourceManger</li>
</ul>
</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sbin/yarn-daemon.sh start resourcemanager</span><br></pre></td></tr></table></figure>
<pre><code>- 启动NodeManager
</code></pre>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sbin/yarn-daemon.sh start nodemanager</span><br></pre></td></tr></table></figure>
<ol start="3">
<li>启动历史服务器</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sbin/mr-jobhistory-daemon.sh start historyserver</span><br></pre></td></tr></table></figure>
<ol start="4">
<li>启动方式</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sbin/start-dfs.sh</span><br><span class="line">sbin/start-yarn.sh</span><br><span class="line">sbin/start-all.sh</span><br></pre></td></tr></table></figure>
<h3 id="实例与测试"><a class="markdownIt-Anchor" href="#实例与测试"></a> 实例与测试</h3>
<p>启动后，用命令<code>jps</code>检查是否启动</p>
<p><img data-src="http://cdn.jasonsoso.com/2015/start-all.png" alt="" /></p>
<p>访问HDFD的NameNode url <code>http://hadoop-yarn.jasonsoso.com:50070/</code></p>
<p><img data-src="http://cdn.jasonsoso.com/2015/50070.png" alt="" /></p>
<p>访问HDFD的Secondary NameNode  url <code>http://hadoop-yarn.jasonsoso.com:50090/</code></p>
<p><img data-src="http://cdn.jasonsoso.com/2015/50090.png" alt="" /></p>
<h3 id="本文配置主要是为伪布式那么hadoop-集群的安装配置大致为如下"><a class="markdownIt-Anchor" href="#本文配置主要是为伪布式那么hadoop-集群的安装配置大致为如下"></a> 本文配置主要是为伪布式，那么Hadoop 集群的安装配置大致为如下:</h3>
<ol>
<li>
<p>选定一台机器作为 Master 主节点</p>
</li>
<li>
<p>在 Master 主机上配置hadoop用户、安装SSH server、安装Java环境</p>
</li>
<li>
<p>在 Master 主机上安装Hadoop，并完成配置</p>
</li>
<li>
<p>在其他主机上配置hadoop用户、安装SSH server、安装Java环境</p>
</li>
<li>
<p>将 Master 主机上的Hadoop目录复制到其他主机上</p>
</li>
<li>
<p>开启、使用 Hadoop</p>
</li>
<li>
<p>需要特别注意的是:</p>
<ul>
<li>网络配置hosts</li>
<li>SSH无密码登陆各节点</li>
<li>部分配置</li>
</ul>
</li>
</ol>
]]></content>
      <tags>
        <tag>分布式</tag>
        <tag>hadoop</tag>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title>搜索引擎ElasticSearch</title>
    <url>/2015/12/elasticsearch/</url>
    <content><![CDATA[<h3 id="第一章-搜索引擎"><a class="markdownIt-Anchor" href="#第一章-搜索引擎"></a> 第一章 搜索引擎</h3>
<h4 id="搜索引擎简单结构"><a class="markdownIt-Anchor" href="#搜索引擎简单结构"></a> 搜索引擎简单结构</h4>
<p><img data-src="http://cdn.jasonsoso.com/2015/index.png" alt="搜索引擎简单结构" /></p>
<h4 id="搜索引擎lucene简介"><a class="markdownIt-Anchor" href="#搜索引擎lucene简介"></a> 搜索引擎Lucene简介</h4>
<ol>
<li>
<p>Logo<br />
<img data-src="http://cdn.jasonsoso.com/2015/lucene_logo_green_300.png" alt="搜索引擎Lucene简介" /></p>
</li>
<li>
<p>简介<br />
Lucene是一套用于全文检索和搜寻的开源程式库，由Apache软件基金会支持和提供。Lucene提供了一个简单却强大的应用程式接口，能够做全文索引和搜寻。在Java开发环境里Lucene是一个成熟的免费开源工具。</p>
</li>
</ol>
<h4 id="搜索引擎lucene优点"><a class="markdownIt-Anchor" href="#搜索引擎lucene优点"></a> 搜索引擎Lucene优点</h4>
<ol>
<li>索引文件格式独立于应用平台。Lucene定义了一套以8位字节为基础的索引文件格式，使得兼容系统或者不同平台的应用能够共享建立的索引文件。</li>
<li>在传统全文检索引擎的倒排索引的基础上，实现了分块索引，能够针对新的文件建立小文件索引，提升索引速度。然后通过与原有索引的合并，达到优化的目的。</li>
<li>优秀的面向对象的系统架构，使得对于Lucene扩展的学习难度降低，方便扩充新功能。</li>
<li>设计了独立于语言和文件格式的文本分析接口，索引器通过接受Token流完成索引文件的创立，用户扩展新的语言和文件格式，只需要实现文本分析的接口。</li>
<li>已经默认实现了一套强大的查询引擎，用户无需自己编写代码即使系统可获得强大的查询能力，Lucene的查询实现中默认实现了布尔操作、模糊查询（Fuzzy Search[11]）、分组查询等等。</li>
</ol>
<h4 id="搜索引擎与数据库的比较"><a class="markdownIt-Anchor" href="#搜索引擎与数据库的比较"></a> 搜索引擎与数据库的比较</h4>
<table>
<thead>
<tr>
<th style="text-align:left">对比项</th>
<th style="text-align:left">全文检索库（Lucene）</th>
<th style="text-align:left">关系型数据库（Oracle）</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">核心功能</td>
<td style="text-align:left">以文本检索为主，插入（insert）、删除（delete）、修改（update）比较麻烦，适合于大文本块的查询。</td>
<td style="text-align:left">插入（insert）、删除（delete）、修改（update）十分方便，有专门的SQL命令，但对于大文本块（如CLOB）类型的检索效率低下。</td>
</tr>
<tr>
<td style="text-align:left">库</td>
<td style="text-align:left">与Oracle类似，都可以建多个库，且各个库的存储位置可以不同。</td>
<td style="text-align:left">可以建多个库，每个库一般都有控制文件和数据文件等，比较复杂。</td>
</tr>
<tr>
<td style="text-align:left">表</td>
<td style="text-align:left">没有严格的表的概念，比如Lucene的表只是由入库时的定义字段松散组成。</td>
<td style="text-align:left">有严格的表结构，有主键，有字段类型等。</td>
</tr>
<tr>
<td style="text-align:left">记录</td>
<td style="text-align:left">由于没有严格表的概念，所以记录体现为一个对象，在Lucene里记录对应的类是Document。</td>
<td style="text-align:left">Record，与表结构对应。</td>
</tr>
<tr>
<td style="text-align:left">字段</td>
<td style="text-align:left">字段类型只有文本和日期两种，字段一般不支持运算，更无函数功能。在Lucene里字段的类是Field，如document（field1,field2…）</td>
<td style="text-align:left">字段类型丰富，功能强大。record（field1,field2…）</td>
</tr>
<tr>
<td style="text-align:left">查询结果集</td>
<td style="text-align:left">在Lucene里表示查询结果集的类是Hits，如hits（doc1,doc2,doc3…）</td>
<td style="text-align:left">在JDBC为例， Resultset（record1,record2,record3…）</td>
</tr>
<tr>
<td style="text-align:left">字符串的搜索</td>
<td style="text-align:left">非常快</td>
<td style="text-align:left">相对慢</td>
</tr>
<tr>
<td style="text-align:left">分词</td>
<td style="text-align:left">可以中文分词</td>
<td style="text-align:left">不可以分词</td>
</tr>
</tbody>
</table>
<h3 id="第二章-elasticsearch简介"><a class="markdownIt-Anchor" href="#第二章-elasticsearch简介"></a> 第二章 Elasticsearch简介</h3>
<h4 id="简介"><a class="markdownIt-Anchor" href="#简介"></a> 简介</h4>
<ol>
<li>ElasticSearch是一个基于Lucene构建的开源，分布式，RESTful搜索引擎。设计用于云计算中，能够达到实时搜索，稳定，可靠，快速，安装使用方便。支持通过HTTP使用JSON进行数据索引。</li>
<li>它基本上所有我想要的特性都包含了，分布式搜索，分布式索引，零配置，自动分片，索引自动负载，节点自动发现，restful风格接口。</li>
<li>扩展性非常好，插件丰富，有很多官方和第三方开发的插件，有分词，同步，数据传输，脚本支持，站点，其他等等；</li>
<li>支持多种语言的客户端，有Perl，Python,Ruby,PHP,Java,NodeJS,.Net,Scala,Go,Erlang…</li>
</ol>
<h4 id="国内外优秀案例"><a class="markdownIt-Anchor" href="#国内外优秀案例"></a> 国内外优秀案例</h4>
<ol>
<li>Github：“GitHub使用ElasticSearch搜索20TB的数据，包括13亿文件和1300亿行代码”</li>
<li>Foursquare：“实时搜索5千万地理位置信息？Foursquare每天使用ElasticSearch做到了”</li>
<li>SoundCloud：“SoundCloud使用ElasticSearch为1.8亿用户提供即时而精准的音乐搜索服务”</li>
<li>Fog Creek ： “Elasticsearch使Fog Creek可以在400亿行代码中进行一个月3千万次的查询”</li>
<li>StumbleUpon : “Elasticsearch是StumbleUpon的关键部件，它每天为社区提供百万次的推荐服务”</li>
<li>Sony：Sony公司使用elasticsearch 作为信息搜索引擎</li>
<li>Infochimps：“在 Infochimps，我们已经索引了25亿文档，总共占用 4TB的空间”。<br />
Infochimps是一家位于德克萨斯州奥斯丁的创业公司，为大数据平台提供商。它主要提供基于hadoop的大数据处理方案。</li>
<li>1号店：每天搜索过亿的商品。</li>
</ol>
<p><img data-src="http://cdn.jasonsoso.com/2015/es1.png" alt="国内外优秀案例" /></p>
<h4 id="elasticsearch的一些概念"><a class="markdownIt-Anchor" href="#elasticsearch的一些概念"></a> Elasticsearch的一些概念</h4>
<ol>
<li>
<p>集群 (cluster)<br />
在一个分布式系统里面,可以通过多个elasticsearch运行实例组成一个集群,这个集群里面有一个节点叫做主节点(master),elasticsearch是去中心化的,所以这里的主节点是动态选举出来的,不存在单点故障。<br />
在同一个子网内，只需要在每个节点上设置相同的集群名,elasticsearch就会自动的把这些集群名相同的节点组成一个集群。节点和节点之间通讯以及节点之间的数据分配和平衡全部由elasticsearch自动管理。<br />
在外部看来elasticsearch就是一个整体。</p>
</li>
<li>
<p>节点(node)<br />
每一个运行实例称为一个节点,每一个运行实例既可以在同一机器上,也可以在不同的机器上.所谓运行实例,就是一个服务器进程.在测试环境内,可以在一台服务器上运行多个服务器进程,在生产环境建议每台服务器运行一个服务器进程<br />
node会使用广播（或指定的多播）来发现一个现有的cluster，并且试图加入该cluster。</p>
</li>
<li>
<p>索引(index)<br />
这里的索引是名词不是动词,在elasticsearch里面支持多个索引。类似于关系数据库里面每一个服务器可以支持多个数据库一样。在每一索引下面又支持多种类型，类似于关系数据库里面的一个数据库可以有多张表。但是本质上和关系数据库有很大的区别。这里暂时可以这么理解</p>
</li>
<li>
<p>分片(shards)<br />
把一个索引分解为多个小的索引，每一个小的索引叫做分片。分片后就可以把各个分片分配到不同的节点中。 Elasticsearch在集群中分布所有的shards，并且在添加删除节点时，自动重新分配。</p>
</li>
<li>
<p>副本(replicas)<br />
代表索引副本，es可以设置多个索引的副本，副本的作用一是提高系统的容错性，当个某个节点某个分片损坏或丢失时可以从副本中恢复。二是提高es的查询效率，es会自动对搜索请求进行负载均衡。</p>
</li>
</ol>
<h4 id="特点优势"><a class="markdownIt-Anchor" href="#特点优势"></a> 特点优势</h4>
<ol>
<li>官网与社区</li>
<li>Apache Lucene（基于 Lucene）</li>
<li>Schema Free(模式自由)</li>
<li>Document Oriented(面向文档型的设计)</li>
<li>Real Time Data &amp; Analytics（实时索引数据）</li>
<li>Distributed（分布式）</li>
<li>High Availability（高可靠性）</li>
<li>其他特性：RESTful API；JSON format；multi-tenancy；full text search；conflict management；per-operation persistence</li>
</ol>
<h4 id="elasticsearch与solr"><a class="markdownIt-Anchor" href="#elasticsearch与solr"></a> Elasticsearch与Solr</h4>
<ol>
<li>realtime-search-solr-vs-elasticsearch<br />
参照http://blog.socialcast.com/realtime-search-solr-vs-elasticsearch/</li>
<li>Apache Solr vs ElasticSearch<br />
参照http://solr-vs-elasticsearch.com/</li>
</ol>
<h3 id="第三章-elasticsearch使用与说明"><a class="markdownIt-Anchor" href="#第三章-elasticsearch使用与说明"></a> 第三章 ElasticSearch使用与说明</h3>
<h4 id="elasticsearch相关知识网站"><a class="markdownIt-Anchor" href="#elasticsearch相关知识网站"></a> ElasticSearch相关知识网站</h4>
<ol>
<li>官网与社区<br />
<a href="http://www.elasticsearch.org/">http://www.elasticsearch.org/</a><br />
<a href="http://www.elasticsearch.com/">http://www.elasticsearch.com/</a></li>
<li>中国Elasticsearch官网<br />
<a href="http://www.elasticsearch.cn/">http://www.elasticsearch.cn/</a></li>
<li>Elasticsearch相关博客<br />
<a href="http://log.medcl.net/">http://log.medcl.net/</a></li>
</ol>
<h4 id="elasticsearch内部架构图"><a class="markdownIt-Anchor" href="#elasticsearch内部架构图"></a> Elasticsearch内部架构图</h4>
<p><img data-src="http://cdn.jasonsoso.com/2015/es2.jpg" alt="es内部架构图" /></p>
<h4 id="elasticsearch部署架构图"><a class="markdownIt-Anchor" href="#elasticsearch部署架构图"></a> ElasticSearch部署架构图</h4>
<p><img data-src="http://cdn.jasonsoso.com/2015/e3.png" alt="es部署架构图" /></p>
<h3 id="第四章-elasticsearch部署"><a class="markdownIt-Anchor" href="#第四章-elasticsearch部署"></a> 第四章 ElasticSearch部署</h3>
<h4 id="linux启动"><a class="markdownIt-Anchor" href="#linux启动"></a> Linux启动</h4>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> elasticsearch/bin/service</span><br><span class="line">./elasticsearch console</span><br></pre></td></tr></table></figure>
<h4 id="window启动"><a class="markdownIt-Anchor" href="#window启动"></a> window启动</h4>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> elasticsearch/bin/service</span><br><span class="line">elasticsearch.bat</span><br></pre></td></tr></table></figure>
<h4 id="工具访问"><a class="markdownIt-Anchor" href="#工具访问"></a> 工具访问</h4>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">http://localhost:9200/_plugin/rtf/</span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>大数据</tag>
        <tag>搜索引擎</tag>
        <tag>ElasticSearch</tag>
      </tags>
  </entry>
  <entry>
    <title>单点登录(SSO)概要设计</title>
    <url>/2016/04/sso/</url>
    <content><![CDATA[<h3 id="第一章-单点登录sso"><a class="markdownIt-Anchor" href="#第一章-单点登录sso"></a> 第一章	： 单点登录(SSO)</h3>
<h4 id="sso诞生的目标"><a class="markdownIt-Anchor" href="#sso诞生的目标"></a> SSO诞生的目标</h4>
<ol>
<li>提高用户体验，提高用户的效率；</li>
<li>资源整合；</li>
<li>简化管理，降低了安全的风险和管理的消耗；</li>
<li>提高服务之间的合作效率</li>
</ol>
<h4 id="sso概述"><a class="markdownIt-Anchor" href="#sso概述"></a> SSO概述</h4>
<ol>
<li>
<p>什么是SSO	<br />
单点登录（ Single Sign-On , 简称 SSO ）是目前比较流行的服务于企业业务整合的解决方案之一， SSO 使得在多个应用系统中，用户只需要 登录一次 就可以访问所有相互信任的应用系统。</p>
</li>
<li>
<p>下图为SSO单点登录物理拓扑图	<br />
<img data-src="http://cdn.jasonsoso.com//2016/sso1.png" alt="SSO单点登录物理拓扑图" title="SSO单点登录物理拓扑图" /></p>
</li>
</ol>
<h4 id="sso的技术的几种技术方案"><a class="markdownIt-Anchor" href="#sso的技术的几种技术方案"></a> SSO的技术的几种技术方案</h4>
<ol>
<li>基于cookies实现<br />
不支持跨域，不推荐</li>
<li>基于session共享来实现<br />
捆绑容器，php与java互通相对麻烦，不推荐</li>
<li>基于身份验证票据ticket来实现<br />
支持跨域，支持语言客户端，推荐</li>
</ol>
<h4 id="sso的技术机制"><a class="markdownIt-Anchor" href="#sso的技术机制"></a> SSO的技术机制</h4>
<ol>
<li>基本原理：<br />
当用户第一次访问应用系统1的时候，因为还没有登录，会被引导到认证系统中进行登录；根据用户提供的登录信息，认证系统进行身份校验，如果通过校验，应该返回给用户一个认证的凭据－－ticket；用户再访问别的应用的时候就会将这个ticket带上，作为自己认证的凭据，应用系统接受到请求之后会把ticket送到认证系统进行校验，检查ticket的合法性。如果通过校验，用户就可以在不用再次登录的情况下访问应用系统2和应用系统3了。</li>
<li>如图基本原理流程：<br />
<img data-src="http://cdn.jasonsoso.com//2016/sso2.png" alt="基本原理" title="基本原理" /></li>
</ol>
<h3 id="第二章-sso的实现-cas"><a class="markdownIt-Anchor" href="#第二章-sso的实现-cas"></a> 第二章 ： SSO的实现 –– CAS###</h3>
<h4 id="cas简介"><a class="markdownIt-Anchor" href="#cas简介"></a> CAS简介</h4>
<p>CAS 是 Yale 大学发起的一个开源项目，旨在为 Web 应用系统提供一种可靠的单点登录方法，CAS 在 2004 年 12 月正式成为 JA-SIG 的一个项目。</p>
<p>CAS 具有以下特点：</p>
<ol>
<li>开源的企业级单点登录解决方案。</li>
<li>Java开源的、多协议的 SSO 解决方案； Protocols ： Custom Protocol 、 CAS 、 OAuth2 、 OpenID 、 RESTful API 、 SAML1.1 、 SAML2.0 等。</li>
<li>支持多种认证机制： Active Directory 、 JAAS 、 JDBC 、 LDAP 、 X.509 Certificates 等。</li>
<li>提供高可用性：通过把认证过的状态数据存储在 TicketRegistry 组件中，这些组件有很多支持分布式环境的实现，如： BerkleyDB 、 Default 、 EhcacheTicketRegistry 、 JDBCTicketRegistry 、 JBOSS</li>
<li>CAS Server 为需要独立部署的 Web 应用。</li>
<li>CAS Client 支持非常多的客户端(这里指单点登录系统中的各个 Web 应用)，包括 Java, .Net, PHP, Perl, Apache, uPortal, Ruby 等。</li>
<li>支持跨域单点登录，支持二级域名的单点登录。</li>
</ol>
<h4 id="cas架构体系"><a class="markdownIt-Anchor" href="#cas架构体系"></a> CAS架构体系</h4>
<p><img data-src="http://cdn.jasonsoso.com//2016/sso3.png" alt="CAS架构体系" title="CAS架构体系" />	<br />
注意：详细请移步到http://jasig.github.io/cas/4.1.x/planning/Architecture.html</p>
<h4 id="cas原理和协议"><a class="markdownIt-Anchor" href="#cas原理和协议"></a> CAS原理和协议</h4>
<p><img data-src="http://cdn.jasonsoso.com//2016/sso4.png" alt="CAS原理和协议" title="CAS原理和协议" /></p>
<h4 id="cas-页面流程与场景"><a class="markdownIt-Anchor" href="#cas-页面流程与场景"></a> CAS 页面流程与场景</h4>
<ol>
<li>以“广告系统”为入口<br />
<img data-src="http://cdn.jasonsoso.com//2016/sso5.png" alt="" /></li>
<li>以“运营系统”为入口<br />
<img data-src="http://cdn.jasonsoso.com//2016/sso6.png" alt="" /></li>
<li>以“SSO系统”为入口<br />
<img data-src="http://cdn.jasonsoso.com//2016/sso7.png" alt="" /></li>
<li>以“账户中心”为入口<br />
<img data-src="http://cdn.jasonsoso.com//2016/sso8.png" alt="" /></li>
</ol>
<p>注意：以上操作一个系统登录，则其他所有系统均可以访问，如果一个系统进行退出，则其他所有系统均已退出</p>
<h3 id="第三章账户中心"><a class="markdownIt-Anchor" href="#第三章账户中心"></a> 第三章	：账户中心</h3>
<h4 id="账户信息管理"><a class="markdownIt-Anchor" href="#账户信息管理"></a> 账户信息管理</h4>
<ol>
<li>
<p>修改个人资料<br />
此功能为修改当前登录者的个人资料，比如邮箱，性别等等。</p>
</li>
<li>
<p>修改登录密码<br />
此功能为修改登录者的密码。</p>
</li>
<li>
<p>账户管理<br />
此功能为有一定权限的账号才可以使用，就是管理全局的账户，针对账户进行新增，修改信息，修改密码，删除，锁定，解锁等等。还支持用户授权管理，针对账户授系统权限和角色权限等等。</p>
</li>
</ol>
<h4 id="账户权限管理"><a class="markdownIt-Anchor" href="#账户权限管理"></a> 账户权限管理</h4>
<ol>
<li>
<p>角色管理<br />
此功能为针对角色进行管理，具体给角色进行赋权。</p>
</li>
<li>
<p>权限资源管理<br />
此功能为针对权限资源、菜单等进行管理。</p>
</li>
</ol>
<h3 id="第四章技术选型"><a class="markdownIt-Anchor" href="#第四章技术选型"></a> 第四章：技术选型</h3>
<h4 id="单点登录sso的实现-cas"><a class="markdownIt-Anchor" href="#单点登录sso的实现-cas"></a> 单点登录SSO的实现 – CAS</h4>
<p>详情请移步：<br />
Cas官网：<a href="http://jasig.github.io/cas/4.1.x/index.html">http://jasig.github.io/cas/4.1.x/index.html</a><br />
Cas代码库：<a href="https://github.com/Jasig/cas">https://github.com/Jasig/cas</a><br />
jasig CAS实现单点登录(数据库认证)：<a href="http://my.oschina.net/indestiny/blog/200768">http://my.oschina.net/indestiny/blog/200768</a></p>
<p>或者参考第二章</p>
<h4 id="权限安全管理-shiro"><a class="markdownIt-Anchor" href="#权限安全管理-shiro"></a> 权限安全管理– shiro</h4>
<p>详情请移步：<br />
Shiro官网：<a href="http://shiro.apache.org/">http://shiro.apache.org/</a><br />
让Apache Shiro保护你的应用：<a href="http://www.infoq.com/cn/articles/apache-shiro">http://www.infoq.com/cn/articles/apache-shiro</a><br />
将 Shiro作为权限基础：<a href="http://www.ibm.com/developerworks/cn/opensource/os-cn-shiro/">http://www.ibm.com/developerworks/cn/opensource/os-cn-shiro/</a></p>
<h4 id="第三方应用登录-oauth-20-协议"><a class="markdownIt-Anchor" href="#第三方应用登录-oauth-20-协议"></a> 第三方应用登录 – OAuth 2.0 协议</h4>
<p>详情请移步：<br />
OAuth 2.0官网：<a href="http://oauth.net/2/">http://oauth.net/2/</a>	<br />
理解OAuth 2.0：<a href="http://www.ruanyifeng.com/blog/2014/05/oauth_2_0.html">http://www.ruanyifeng.com/blog/2014/05/oauth_2_0.html</a></p>
]]></content>
      <tags>
        <tag>单点登录</tag>
        <tag>架构</tag>
        <tag>SSO</tag>
      </tags>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/2022/03/hello-world/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="quick-start"><a class="markdownIt-Anchor" href="#quick-start"></a> Quick Start</h2>
<h3 id="create-a-new-post"><a class="markdownIt-Anchor" href="#create-a-new-post"></a> Create a new post</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="run-server"><a class="markdownIt-Anchor" href="#run-server"></a> Run server</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="generate-static-files"><a class="markdownIt-Anchor" href="#generate-static-files"></a> Generate static files</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="deploy-to-remote-sites"><a class="markdownIt-Anchor" href="#deploy-to-remote-sites"></a> Deploy to remote sites</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>
]]></content>
      <categories>
        <category>备忘录</category>
      </categories>
      <tags>
        <tag>hello wold</tag>
      </tags>
  </entry>
</search>
